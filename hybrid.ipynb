{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/82p978c554zg2gg3cn3vrbq00000gn/T/ipykernel_4102/501569260.py:1: DtypeWarning: Columns (3,4,5,16,17,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('limited_dataset.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 50</th>\n",
       "      <th>Unnamed: 51</th>\n",
       "      <th>Unnamed: 52</th>\n",
       "      <th>Unnamed: 53</th>\n",
       "      <th>Unnamed: 54</th>\n",
       "      <th>Unnamed: 55</th>\n",
       "      <th>Unnamed: 56</th>\n",
       "      <th>Unnamed: 57</th>\n",
       "      <th>Unnamed: 58</th>\n",
       "      <th>Unnamed: 59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       artists album_name track_name popularity duration_ms explicit  \\\n",
       "0  Gen Hoshino     Comedy     Comedy         73      230666    FALSE   \n",
       "1  Gen Hoshino     Comedy     Comedy         73      230666    FALSE   \n",
       "2  Gen Hoshino     Comedy     Comedy         73      230666    FALSE   \n",
       "3  Gen Hoshino     Comedy     Comedy         73      230666    FALSE   \n",
       "4  Gen Hoshino     Comedy     Comedy         73      230666    FALSE   \n",
       "\n",
       "   danceability  energy  key  loudness  ...  Unnamed: 50  Unnamed: 51  \\\n",
       "0         0.676   0.461  1.0    -6.746  ...          NaN          NaN   \n",
       "1         0.676   0.461  1.0    -6.746  ...          NaN          NaN   \n",
       "2         0.676   0.461  1.0    -6.746  ...          NaN          NaN   \n",
       "3         0.676   0.461  1.0    -6.746  ...          NaN          NaN   \n",
       "4         0.676   0.461  1.0    -6.746  ...          NaN          NaN   \n",
       "\n",
       "   Unnamed: 52  Unnamed: 53  Unnamed: 54  Unnamed: 55 Unnamed: 56 Unnamed: 57  \\\n",
       "0          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "1          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "2          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "3          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "4          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 58 Unnamed: 59  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('limited_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110000 entries, 0 to 109999\n",
      "Data columns (total 60 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   artists           110000 non-null  object \n",
      " 1   album_name        110000 non-null  object \n",
      " 2   track_name        110000 non-null  object \n",
      " 3   popularity        110000 non-null  object \n",
      " 4   duration_ms       110000 non-null  object \n",
      " 5   explicit          110000 non-null  object \n",
      " 6   danceability      110000 non-null  float64\n",
      " 7   energy            110000 non-null  float64\n",
      " 8   key               110000 non-null  float64\n",
      " 9   loudness          110000 non-null  float64\n",
      " 10  mode              110000 non-null  float64\n",
      " 11  speechiness       110000 non-null  float64\n",
      " 12  acousticness      110000 non-null  float64\n",
      " 13  instrumentalness  110000 non-null  float64\n",
      " 14  liveness          110000 non-null  float64\n",
      " 15  valence           110000 non-null  float64\n",
      " 16  tempo             110000 non-null  object \n",
      " 17  time_signature    110000 non-null  object \n",
      " 18  track_genre       110000 non-null  object \n",
      " 19  artist_name       110000 non-null  object \n",
      " 20  date_added        109999 non-null  object \n",
      " 21  playlist_name     109884 non-null  object \n",
      " 22  Unnamed: 22       19 non-null      object \n",
      " 23  Unnamed: 23       9 non-null       object \n",
      " 24  Unnamed: 24       0 non-null       float64\n",
      " 25  Unnamed: 25       0 non-null       float64\n",
      " 26  Unnamed: 26       0 non-null       float64\n",
      " 27  Unnamed: 27       0 non-null       float64\n",
      " 28  Unnamed: 28       0 non-null       float64\n",
      " 29  Unnamed: 29       0 non-null       float64\n",
      " 30  Unnamed: 30       0 non-null       float64\n",
      " 31  Unnamed: 31       0 non-null       float64\n",
      " 32  Unnamed: 32       0 non-null       float64\n",
      " 33  Unnamed: 33       0 non-null       float64\n",
      " 34  Unnamed: 34       0 non-null       float64\n",
      " 35  Unnamed: 35       0 non-null       float64\n",
      " 36  Unnamed: 36       0 non-null       float64\n",
      " 37  Unnamed: 37       0 non-null       float64\n",
      " 38  Unnamed: 38       0 non-null       float64\n",
      " 39  Unnamed: 39       0 non-null       float64\n",
      " 40  Unnamed: 40       0 non-null       float64\n",
      " 41  Unnamed: 41       0 non-null       float64\n",
      " 42  Unnamed: 42       0 non-null       float64\n",
      " 43  Unnamed: 43       0 non-null       float64\n",
      " 44  Unnamed: 44       0 non-null       float64\n",
      " 45  Unnamed: 45       0 non-null       float64\n",
      " 46  Unnamed: 46       0 non-null       float64\n",
      " 47  Unnamed: 47       0 non-null       float64\n",
      " 48  Unnamed: 48       0 non-null       float64\n",
      " 49  Unnamed: 49       0 non-null       float64\n",
      " 50  Unnamed: 50       0 non-null       float64\n",
      " 51  Unnamed: 51       0 non-null       float64\n",
      " 52  Unnamed: 52       0 non-null       float64\n",
      " 53  Unnamed: 53       0 non-null       float64\n",
      " 54  Unnamed: 54       0 non-null       float64\n",
      " 55  Unnamed: 55       0 non-null       float64\n",
      " 56  Unnamed: 56       0 non-null       float64\n",
      " 57  Unnamed: 57       0 non-null       float64\n",
      " 58  Unnamed: 58       0 non-null       float64\n",
      " 59  Unnamed: 59       0 non-null       float64\n",
      "dtypes: float64(46), object(14)\n",
      "memory usage: 50.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/82p978c554zg2gg3cn3vrbq00000gn/T/ipykernel_4102/3677905146.py:11: DtypeWarning: Columns (3,4,5,16,17,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('limited_dataset.csv')\n",
      "/Users/arkdawg/miniforge3/envs/dsc80/lib/python3.12/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 8 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "/Users/arkdawg/miniforge3/envs/dsc80/lib/python3.12/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.002482891082763672 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40348afc072047769f0883b86c2598af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('limited_dataset.csv')\n",
    "\n",
    "df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')\n",
    "df = df.dropna(subset=['date_added'])\n",
    "\n",
    "# Remove last 3 songs from each playlist\n",
    "data_sorted = df.sort_values(by=['playlist_name', 'date_added'])\n",
    "train_data, removed_songs = [], []\n",
    "\n",
    "for playlist, group in data_sorted.groupby('playlist_name'):\n",
    "    if len(group) > 3:\n",
    "        removed_songs.append(group.tail(3))\n",
    "        train_data.append(group.head(len(group) - 3))\n",
    "\n",
    "train_data = pd.concat(train_data)\n",
    "removed_songs = pd.concat(removed_songs)\n",
    "\n",
    "# Encode categorical variables\n",
    "track_encoder = LabelEncoder()\n",
    "df[\"encoded_track\"] = track_encoder.fit_transform(df[\"track_name\"])\n",
    "playlist_encoder = LabelEncoder()\n",
    "df[\"encoded_playlist\"] = playlist_encoder.fit_transform(df[\"playlist_name\"])\n",
    "\n",
    "# Create interaction matrix\n",
    "interaction_matrix = coo_matrix((np.ones(len(df)), (df['encoded_playlist'], df['encoded_track'])))\n",
    "\n",
    "# Train ALS model\n",
    "als_model = AlternatingLeastSquares(factors=50, regularization=0.1, iterations=20)\n",
    "als_model.fit(interaction_matrix)\n",
    "\n",
    "# Function to recommend songs\n",
    "def recommend_songs(input_tracks, top_n=3):\n",
    "    input_tracks_encoded = [track_encoder.transform([t])[0] for t in input_tracks if t in track_encoder.classes_]\n",
    "    if not input_tracks_encoded:\n",
    "        return []\n",
    "    \n",
    "    recommendations = set()\n",
    "    for track in input_tracks_encoded:\n",
    "        recs = als_model.similar_items(track, N=top_n+1)[1:]\n",
    "        recommendations.update([track_encoder.inverse_transform([r[0]])[0] for r in recs])\n",
    "    \n",
    "    return list(recommendations)[:top_n]\n",
    "\n",
    "# Create song similarity matrix\n",
    "num_features = [\"danceability\", \"energy\", \"valence\", \"tempo\", \"loudness\", \"speechiness\", \"acousticness\", \"instrumentalness\"]\n",
    "scaler = MinMaxScaler()\n",
    "df[num_features] = scaler.fit_transform(df[num_features])\n",
    "\n",
    "feature_vectors = df[num_features].values\n",
    "song_similarity_matrix = cosine_similarity(feature_vectors)\n",
    "song_similarity_df = pd.DataFrame(song_similarity_matrix, index=df['track_name'], columns=df['track_name'])\n",
    "\n",
    "# Function to compute similarity\n",
    "def compute_similarity(song1, song2, song_similarity_df):\n",
    "    if song1 in song_similarity_df.index and song2 in song_similarity_df.columns:\n",
    "        return song_similarity_df.loc[song1, song2]\n",
    "    return 0\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(recommended_songs, removed_songs, song_similarity_df):\n",
    "    all_errors = []\n",
    "    for _, removed_group in removed_songs.groupby('playlist_name'):\n",
    "        playlist_songs = removed_group['track_name'].tolist()\n",
    "        for song in playlist_songs:\n",
    "            recommended_song = recommended_songs.get(song, None)\n",
    "            if recommended_song:\n",
    "                distances = [compute_similarity(song, recommended, song_similarity_df) for recommended in recommended_song]\n",
    "                all_errors.append(min(distances))\n",
    "    return sqrt(mean_squared_error(np.ones(len(all_errors)), all_errors))\n",
    "\n",
    "# Generate recommendations for first 100 playlists\n",
    "all_recommended_songs = {}\n",
    "for playlist, group in list(data_sorted.groupby('playlist_name'))[:100]:\n",
    "    playlist_songs = group['track_name'].tolist()\n",
    "    all_recommended_songs[playlist] = recommend_songs(playlist_songs, top_n=1)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_value = calculate_rmse(all_recommended_songs, removed_songs, song_similarity_df)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def random_playlist_recommendations(num_samples=5, top_n=3):\n",
    "    unique_playlists = df[\"playlist_name\"].unique()\n",
    "    recommendations = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Randomly select a playlist\n",
    "        playlist_name = random.choice(unique_playlists)\n",
    "        # Get songs from the selected playlist\n",
    "        playlist_songs = df[df[\"playlist_name\"] == playlist_name][\"track_id\"].unique()\n",
    "\n",
    "        # Randomly select some songs from the playlist as input\n",
    "        input_tracks = random.sample(list(playlist_songs), min(3, len(playlist_songs)))  # Choose up to 3 songs\n",
    "\n",
    "        # Get recommendations\n",
    "        recommended_songs = recommend_songs(input_tracks, top_n)\n",
    "        recommendations.append((playlist_name, input_tracks, recommended_songs))\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model():\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[[\"track_id\", \"playlist_name\"]],\n",
    "        np.ones(len(df)),  # Assuming all songs in playlists are positive\n",
    "        test_size=0.7,  # Use 20% of the data for testing\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    valid_train_mask = X_train[\"track_id\"].isin(track_encoder.classes_) & X_train[\"playlist_name\"].isin(playlist_encoder.classes_)\n",
    "    X_train_valid = X_train[valid_train_mask]\n",
    "\n",
    "    # Ensure valid data\n",
    "    if X_train_valid.empty:\n",
    "        print(\"No valid training data found after filtering.\")\n",
    "        return\n",
    "\n",
    "    # Encode training data\n",
    "    X_train_encoded = [\n",
    "        track_encoder.transform(X_train_valid[\"track_id\"]),\n",
    "        playlist_encoder.transform(X_train_valid[\"playlist_name\"])\n",
    "    ]\n",
    "    \n",
    "    # Get corresponding y_train\n",
    "    y_train_valid = y_train[valid_train_mask]\n",
    "\n",
    "    # Ensure sizes match\n",
    "    if len(X_train_encoded[0]) != len(y_train_valid):\n",
    "        print(f\"Size mismatch: X_train_encoded: {len(X_train_encoded[0])}, y_train_valid: {len(y_train_valid)}\")\n",
    "        return\n",
    "\n",
    "    model.fit(X_train_encoded, y_train_valid, epochs=10, batch_size=64)\n",
    "\n",
    "    # Test the model on the test set\n",
    "    valid_test_mask = X_test[\"track_id\"].isin(track_encoder.classes_) & X_test[\"playlist_name\"].isin(playlist_encoder.classes_)\n",
    "    X_test_valid = X_test[valid_test_mask]\n",
    "    \n",
    "    if X_test_valid.empty:\n",
    "        print(\"No valid test data found after filtering.\")\n",
    "        return\n",
    "\n",
    "    # Encode test data\n",
    "    X_test_encoded = [\n",
    "        track_encoder.transform(X_test_valid[\"track_id\"]),\n",
    "        playlist_encoder.transform(X_test_valid[\"playlist_name\"])\n",
    "    ]\n",
    "    \n",
    "    # Get corresponding y_test\n",
    "    y_test_valid = y_test[valid_test_mask]\n",
    "    \n",
    "    if len(X_test_encoded[0]) != len(y_test_valid):\n",
    "        print(f\"Size mismatch: X_test_encoded: {len(X_test_encoded[0])}, y_test_valid: {len(y_test_valid)}\")\n",
    "        return\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test_valid, y_pred_classes)\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Call the evaluate function\n",
    "evaluate_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# df = pd.read_csv('subset_combined_dataset.csv')\n",
    "df = pd.read_csv('limited_dataset.csv')\n",
    "\n",
    "\n",
    "# Convert track_id to string\n",
    "df['track_name'] = df['track_id'].astype(str)\n",
    "\n",
    "# Encode categorical variables\n",
    "track_encoder = LabelEncoder()\n",
    "df[\"encoded_track_id\"] = track_encoder.fit_transform(df[\"track_id\"])\n",
    "\n",
    "playlist_encoder = LabelEncoder()\n",
    "df[\"playlist_name\"] = playlist_encoder.fit_transform(df[\"playlist_name\"])\n",
    "\n",
    "# Normalize numeric features\n",
    "num_features = [\"danceability\", \"energy\", \"valence\", \"tempo\", \"loudness\", \"speechiness\", \"acousticness\", \"instrumentalness\"]\n",
    "scaler = MinMaxScaler()\n",
    "df[num_features] = scaler.fit_transform(df[num_features])\n",
    "\n",
    "# Define model hyperparameters\n",
    "embedding_dim = 32\n",
    "n_tracks = df[\"encoded_track_id\"].nunique()\n",
    "n_playlists = df[\"playlist_name\"].nunique()\n",
    "\n",
    "# Define inputs\n",
    "track_input = Input(shape=(1,))\n",
    "playlist_input = Input(shape=(1,))\n",
    "\n",
    "# Embedding layers\n",
    "track_embedding = Embedding(n_tracks, embedding_dim)(track_input)\n",
    "playlist_embedding = Embedding(n_playlists, embedding_dim)(playlist_input)\n",
    "\n",
    "# Flatten embeddings\n",
    "track_vec = Flatten()(track_embedding)\n",
    "playlist_vec = Flatten()(playlist_embedding)\n",
    "\n",
    "# Compute interaction\n",
    "dot_product = Dot(axes=1)([track_vec, playlist_vec])\n",
    "\n",
    "# Additional dense layers for learning non-linear relationships\n",
    "concat = Concatenate()([dot_product, track_vec, playlist_vec])\n",
    "dense1 = Dense(64, activation=\"relu\")(concat)\n",
    "dense2 = Dense(32, activation=\"relu\")(dense1)\n",
    "output = Dense(1, activation=\"sigmoid\")(dense2)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=[track_input, playlist_input], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Prepare training data\n",
    "X_train = [df[\"encoded_track_id\"].values, df[\"playlist_name\"].values]\n",
    "y_train = np.ones(len(df))  # Implicit feedback (all songs in playlists are positive)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64)\n",
    "\n",
    "def recommend_songs(input_tracks, top_n=3):\n",
    "    # Ensure input_tracks are converted to strings for consistency\n",
    "    input_tracks = [str(track) for track in input_tracks]\n",
    "    input_tracks_encoded = track_encoder.transform([t for t in input_tracks if t in track_encoder.classes_])\n",
    "    \n",
    "    if len(input_tracks_encoded) == 0:\n",
    "        print(\"No valid input tracks found in the dataset.\")\n",
    "        return []\n",
    "    \n",
    "    playlist_ids = np.arange(n_playlists)\n",
    "    \n",
    "    scores = model.predict([\n",
    "        np.repeat(input_tracks_encoded, len(playlist_ids)), \n",
    "        np.tile(playlist_ids, len(input_tracks_encoded))\n",
    "    ])\n",
    "    \n",
    "    avg_scores = np.mean(scores, axis=0)  # Average predictions for multiple input songs\n",
    "    top_indices = np.argsort(avg_scores)[-top_n:][::-1]  # Get top-N recommendations\n",
    "    \n",
    "    # Ensure recommended indices exist in track_encoder\n",
    "    valid_indices = [idx for idx in top_indices if idx < len(track_encoder.classes_)]\n",
    "    \n",
    "    if not valid_indices:\n",
    "        print(\"No valid recommendations found.\")\n",
    "        return []\n",
    "    \n",
    "    # To ensure uniqueness, you can convert the result to a set and back to a list\n",
    "    recommended_tracks = list(set(track_encoder.inverse_transform(valid_indices)))\n",
    "    \n",
    "    return recommended_tracks[:top_n]  # Return the top N unique recommendations\n",
    "\n",
    "def get_song_name(recommend_song_ids):\n",
    "    # Ensure the input is a list of strings\n",
    "    if isinstance(recommend_song_ids, np.ndarray):\n",
    "        recommend_song_ids = recommend_song_ids.tolist()\n",
    "    elif not isinstance(recommend_song_ids, list):\n",
    "        recommend_song_ids = [recommend_song_ids]  # Convert a single ID to a list\n",
    "\n",
    "    # Convert all track IDs to string (to match df[\"track_id\"])\n",
    "    recommend_song_ids = [str(track_id) for track_id in recommend_song_ids]\n",
    "\n",
    "    # Filter DataFrame for matching track IDs\n",
    "    recommended_songs = df[df[\"track_id\"].isin(recommend_song_ids)][[\"track_id\", \"track_name\"]].drop_duplicates()\n",
    "\n",
    "    return recommended_songs[\"track_name\"].tolist()\n",
    "\n",
    "# Example usage\n",
    "input_tracks = [\"6lfxq3CG4xtTiEg7opyCyx\", \"1EzrEOXmMH3G43AXT1y7pA\", \"5ivF4eQBqJiVL5IAE9jRyl\"]  # Replace with actual track IDs\n",
    "recommended_songs = recommend_songs(input_tracks)\n",
    "print_names = get_song_name(recommended_songs)\n",
    "print(\"Recommended Songs:\", print_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_model(df, model, track_encoder, playlist_encoder, num_features):\n",
    "    playlist_mse = []\n",
    "    \n",
    "    for playlist, group in df.groupby(\"playlist_name\"):\n",
    "        if len(group) < 4:\n",
    "            continue  # Skip short playlists\n",
    "        \n",
    "        train_tracks = group.iloc[:-3]  # All but the last 3 tracks\n",
    "        test_tracks = group.iloc[-3:]  # Last 3 tracks\n",
    "        \n",
    "        playlist_encoded = playlist_encoder.transform([playlist])[0]\n",
    "        train_track_ids = train_tracks[\"encoded_track_id\"].values\n",
    "        test_features = test_tracks[num_features].values  # Numerical features of excluded songs\n",
    "        \n",
    "        # Predict next track\n",
    "        predictions = model.predict([\n",
    "            np.tile(train_track_ids, len(track_encoder.classes_)),\n",
    "            np.repeat(playlist_encoded, len(track_encoder.classes_))\n",
    "        ])\n",
    "        \n",
    "        predicted_track_idx = np.argmax(predictions)  # Track with highest predicted score\n",
    "        predicted_track_id = track_encoder.inverse_transform([predicted_track_idx])[0]\n",
    "        \n",
    "        # Retrieve numerical features of predicted track\n",
    "        predicted_features = df[df[\"track_id\"] == predicted_track_id][num_features].values\n",
    "        if len(predicted_features) == 0:\n",
    "            continue  # Skip if the predicted track is missing from the dataset\n",
    "        \n",
    "        # Compute MSE against test tracks\n",
    "        mse = min(mean_squared_error(test_features[i], predicted_features[0]) for i in range(len(test_features)))\n",
    "        playlist_mse.append(mse)\n",
    "    \n",
    "    return np.mean(playlist_mse) if playlist_mse else None\n",
    "\n",
    "# Evaluate model\n",
    "mse_score = evaluate_model(df, model, track_encoder, playlist_encoder, num_features)\n",
    "print(\"Mean MSE across playlists:\", mse_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def random_playlist_recommendations(num_samples=5, top_n=3):\n",
    "    unique_playlists = df[\"playlist_name\"].unique()\n",
    "    recommendations = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Randomly select a playlist\n",
    "        playlist_name = random.choice(unique_playlists)\n",
    "        # Get songs from the selected playlist\n",
    "        playlist_songs = df[df[\"playlist_name\"] == playlist_name][\"track_id\"].unique()\n",
    "\n",
    "        # Randomly select some songs from the playlist as input\n",
    "        input_tracks = random.sample(list(playlist_songs), min(3, len(playlist_songs)))  # Choose up to 3 songs\n",
    "\n",
    "        # Get recommendations\n",
    "        recommended_songs = recommend_songs(input_tracks, top_n)\n",
    "        recommendations.append((playlist_name, input_tracks, recommended_songs))\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model():\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[[\"track_id\", \"playlist_name\"]],\n",
    "        np.ones(len(df)),  # Assuming all songs in playlists are positive\n",
    "        test_size=0.7,  # Use 20% of the data for testing\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    valid_train_mask = X_train[\"track_id\"].isin(track_encoder.classes_) & X_train[\"playlist_name\"].isin(playlist_encoder.classes_)\n",
    "    X_train_valid = X_train[valid_train_mask]\n",
    "\n",
    "    # Ensure valid data\n",
    "    if X_train_valid.empty:\n",
    "        print(\"No valid training data found after filtering.\")\n",
    "        return\n",
    "\n",
    "    # Encode training data\n",
    "    X_train_encoded = [\n",
    "        track_encoder.transform(X_train_valid[\"track_id\"]),\n",
    "        playlist_encoder.transform(X_train_valid[\"playlist_name\"])\n",
    "    ]\n",
    "    \n",
    "    # Get corresponding y_train\n",
    "    y_train_valid = y_train[valid_train_mask]\n",
    "\n",
    "    # Ensure sizes match\n",
    "    if len(X_train_encoded[0]) != len(y_train_valid):\n",
    "        print(f\"Size mismatch: X_train_encoded: {len(X_train_encoded[0])}, y_train_valid: {len(y_train_valid)}\")\n",
    "        return\n",
    "\n",
    "    model.fit(X_train_encoded, y_train_valid, epochs=10, batch_size=64)\n",
    "\n",
    "    # Test the model on the test set\n",
    "    valid_test_mask = X_test[\"track_id\"].isin(track_encoder.classes_) & X_test[\"playlist_name\"].isin(playlist_encoder.classes_)\n",
    "    X_test_valid = X_test[valid_test_mask]\n",
    "    \n",
    "    if X_test_valid.empty:\n",
    "        print(\"No valid test data found after filtering.\")\n",
    "        return\n",
    "\n",
    "    # Encode test data\n",
    "    X_test_encoded = [\n",
    "        track_encoder.transform(X_test_valid[\"track_id\"]),\n",
    "        playlist_encoder.transform(X_test_valid[\"playlist_name\"])\n",
    "    ]\n",
    "    \n",
    "    # Get corresponding y_test\n",
    "    y_test_valid = y_test[valid_test_mask]\n",
    "    \n",
    "    if len(X_test_encoded[0]) != len(y_test_valid):\n",
    "        print(f\"Size mismatch: X_test_encoded: {len(X_test_encoded[0])}, y_test_valid: {len(y_test_valid)}\")\n",
    "        return\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test_valid, y_pred_classes)\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Call the evaluate function\n",
    "evaluate_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random playlist recommendations\n",
    "recommendations = random_playlist_recommendations(num_samples=5, top_n=3)\n",
    "for playlist_name, input_tracks, recommended_songs in recommendations:\n",
    "    print(f\"Playlist: {playlist_name}, Input Tracks: {input_tracks}, Recommended Songs: {recommended_songs}\")\n",
    "\n",
    "# Evaluate model performance\n",
    "evaluate_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('cleaned_dataset_v2.csv')\n",
    "\n",
    "# Define a Reader object\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "# Create a Surprise dataset from the DataFrame\n",
    "data = Dataset.load_from_df(df[['playlist_name', 'track_id', 'rating']], reader)\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(playlist_name):\n",
    "    # Filter the playlist data\n",
    "    playlist_data = df[df['playlist_name'] == playlist_name]\n",
    "    \n",
    "    # Check if the playlist has more than 3 songs\n",
    "    if len(playlist_data) <= 3:\n",
    "        print(\"Playlist must have more than 3 songs.\")\n",
    "        return None\n",
    "    \n",
    "    # Separate the last three songs for prediction\n",
    "    hidden_songs = playlist_data['track_id'].values[-3:]\n",
    "    train_data = playlist_data.iloc[:-3]\n",
    "    \n",
    "    # Create a new dataset for training\n",
    "    trainset = Dataset.load_from_df(train_data[['playlist_name', 'track_id', 'rating']], reader).build_full_trainset()\n",
    "\n",
    "    # User-based collaborative filtering model\n",
    "    model = KNNBasic(sim_options={'user_based': True})\n",
    "    model.fit(trainset)\n",
    "\n",
    "    # Prepare test set for prediction\n",
    "    testset = [(trainset.to_inner_uid(train_data['playlist_name'].iloc[0]), \n",
    "                 trainset.to_inner_iid(track_id)) for track_id in hidden_songs]\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.test(testset)\n",
    "    \n",
    "    # Evaluate the predictions\n",
    "    predicted_tracks = [track_encoder.inverse_transform([pred[1]])[0] for pred in predictions if pred.est >= 0.5]\n",
    "    \n",
    "    return predicted_tracks, hidden_songs.tolist()\n",
    "\n",
    "# Example usage\n",
    "playlist_name = \"example_playlist\"  # Replace with actual playlist name\n",
    "predicted_songs, actual_songs = evaluate_model(playlist_name)\n",
    "print(\"Predicted Songs:\", predicted_songs)\n",
    "print(\"Actual Songs:\", actual_songs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
